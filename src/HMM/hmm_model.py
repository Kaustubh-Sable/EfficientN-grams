# -*- coding: utf-8 -*-
"""HMM Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QmaSQdzch6RPLpvdXJcHNaLMa0UslaFN
"""

from google.colab import drive
drive.mount('/gdrive')

import os
print(os.listdir('../gdrive/My Drive/NLP/Final Project/'))
os.chdir('../gdrive/My Drive/NLP/Final Project/')

blogs = open('LSTM/republic.txt', 'r')
text = blogs.read()
blogs.close()

corpus = text
print(len(corpus))

# We will remove double quotes, !, ? $, #, etc
# specify to translate chars 
str1 = ""
# specify to replace with 
str2 = ""
# delete chars 
str3 = "\"!?#$%^&*+"

trg = corpus
table = trg.maketrans(str1, str2, str3)
corpus = trg.translate(table)

print(len(corpus))

words = corpus.split()
print (len(words))

# convert to lower case
words = [word.lower() for word in words]

# The data set is cleaned. So, let's try to build a frequency table for n-grams
print(len(set(words)))
# Vocab size
import nltk
freq_dist = nltk.FreqDist(words)

freq_dist.most_common(10) # the most common words in our corpus.

"""Finding out the n-grams that are present in the data set."""

from nltk.util import ngrams

esBigrams = ngrams(words, 2)

import collections
esBigramFreq = collections.Counter(esBigrams)

esBigramFreq.most_common(10)

esTrigrams = ngrams(words, 3)
esTrigramFreq = collections.Counter(esTrigrams)

esTrigramFreq.most_common(10)

esQuadgrams = ngrams(words, 4)
esQuadgramFreq = collections.Counter(esQuadgrams)
esQuadgramFreq.most_common(10)

# Dumbest and most basic model using a simple Markov Chain
# Principal Random walk
# Given a seed word, enter the dictionary entry with that word as a key and 
# Randomly select any word that is present into it's adjacency list.
def build_chain(text, chain = {}):
    words = text
    index = 1
    for word in words[index:]:
        key = words[index - 1]
        if key in chain:
            chain[key].append(word)
        else:
            chain[key] = [word]
        index += 1
    return chain

"""## Build a HMM Model"""

import random

def generate_message(key, chain, count = 100):
  prediction = chain[key][random.randint(0, len(chain[key]))]
  return prediction

"""### Next word prediction using the graph generated by HMM
For simplicity, we are using random word selection from the adjacency list.
"""

print(generate_message('the', chain, count=1))

print(generate_message('with', chain, count=1))

print(generate_message('which', chain, count=1))

random.randint(0, len(chain['the']))