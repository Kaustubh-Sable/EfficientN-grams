{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Level LSTM Config 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMemBHD5Is_0",
        "colab_type": "text"
      },
      "source": [
        "**Word Level LSTM for trigrams** (sequence length: 2):\n",
        "\n",
        "This model predicts a word given two prior words. The code broadly consists of three parts:\n",
        "\n",
        "*   Training the LSTM model and save it to a file.\n",
        "*   Load the model from the file.\n",
        "*   Calculate the accuracy of the model based on the frequency-based N-gram (trigram in this case) counts.\n",
        "\n",
        "Pros:\n",
        "- Offers less sparsity and shorter sequence lengths in contrast to character-level alternatives.\n",
        "- No post-processing required.\n",
        "- Model trained on sequence length of n-words works well for all values less than n.\n",
        "- Good at capturing long-distance dependencies.\n",
        "\n",
        "Cons:\n",
        "- They are unable to generate a word which is unseen/rare during training, hence, suffer from the Out-Of-Vocabulary (OOV) problem. One solution is to have a large dictionary, but still, that increases the time and space complexity of the network and also, the same problem would appear for every new word.\n",
        "- Softmax used in the output layer is often computationaly intensive.\n",
        "- Harder to model languages with a rich morphology such as Finish, Turkish, Russian etc.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-1WNNP7lkPU",
        "colab_type": "code",
        "outputId": "debfa02d-1fe0-4e9e-967f-15374017ee1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTn14jP4lpk_",
        "colab_type": "code",
        "outputId": "7c96a72a-68ab-4e72-8a14-49b8cebfdb8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ../gdrive/My\\ Drive/NLP/Project/Final\\ Project/LSTM/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/NLP/Project/Final Project/LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWOIekeu-n2I",
        "colab_type": "code",
        "outputId": "996228b5-ffbc-4cf3-b905-a75d110151eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'10 letters window 10 epochs of LSTM Next word Prediction.ipynb'\n",
            "'10 letters window 30 epochs of LSTM Next word Prediction.ipynb'\n",
            " \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/\n",
            " data.txt\n",
            " examples.txt\n",
            "'LSTM Next word Prediction.ipynb'\n",
            " lstm_train.py\n",
            " model.h5\n",
            " pima_indians.txt\n",
            " republic.txt\n",
            " requirements.txt\n",
            " tokenizer.pkl\n",
            " trigram_model.png\n",
            " vocabulary.txt\n",
            "'Word Level LSTM.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZjH0GA0m60Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmiEDo5n17vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuPdxkZ6X1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load dataset\n",
        "in_filename = 'republic.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxKACktEhNQL",
        "colab_type": "code",
        "outputId": "a2ccfaf7-81b9-420a-942f-88b1e3ab3806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "sequences[1:10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [30, 1614, 5, 26, 1, 163, 2, 2549, 2550, 35, 44, 2871, 3, 28],\n",
              " [568, 44, 3940, 4907, 21, 37, 1062, 73, 235, 73, 248, 13],\n",
              " [2551, 163, 73, 157, 1, 379, 2, 1, 286, 264, 1178, 1325],\n",
              " [28, 30, 1614, 13, 3323, 35, 2552, 264, 1404],\n",
              " [],\n",
              " [],\n",
              " [2069, 1, 227],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7Df-vKhpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in sequences for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAOOpT55jARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 2\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(flat_list) - seq_length, 1):\n",
        "\tseq_in = flat_list[i:i + seq_length]\n",
        "\tseq_out = flat_list[i + seq_length]\n",
        "\tdataX.append(seq_in)\n",
        "\tdataY.append(seq_out)\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Ba1MRjlNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = array(dataX)\n",
        "dataY = array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqbJSLSj9aw",
        "colab_type": "code",
        "outputId": "439d93c7-c004-463a-d188-38ff25c76e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataX.shape, dataY.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((221275, 2), (221275,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQJLFWPbqbl",
        "colab_type": "code",
        "outputId": "f7e33328-842c-4fcc-faa4-d43b30a5f68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separate into input and output\n",
        "X, y = dataX, dataY\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = dataX.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 2, 50)             551800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 2, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11036)             1114636   \n",
            "=================================================================\n",
            "Total params: 1,817,336\n",
            "Trainable params: 1,817,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "221275/221275 [==============================] - 32s 144us/step - loss: 6.3449 - acc: 0.0824\n",
            "Epoch 2/50\n",
            "221275/221275 [==============================] - 27s 120us/step - loss: 5.7487 - acc: 0.1304\n",
            "Epoch 3/50\n",
            "221275/221275 [==============================] - 27s 120us/step - loss: 5.4465 - acc: 0.1559\n",
            "Epoch 4/50\n",
            "221275/221275 [==============================] - 27s 121us/step - loss: 5.2445 - acc: 0.1692\n",
            "Epoch 5/50\n",
            "221275/221275 [==============================] - 26s 119us/step - loss: 5.0816 - acc: 0.1803\n",
            "Epoch 6/50\n",
            "221275/221275 [==============================] - 26s 118us/step - loss: 4.9398 - acc: 0.1887\n",
            "Epoch 7/50\n",
            "221275/221275 [==============================] - 26s 119us/step - loss: 4.8092 - acc: 0.1952\n",
            "Epoch 8/50\n",
            "221275/221275 [==============================] - 26s 118us/step - loss: 4.6869 - acc: 0.2025\n",
            "Epoch 9/50\n",
            "221275/221275 [==============================] - 26s 118us/step - loss: 4.5721 - acc: 0.2080\n",
            "Epoch 10/50\n",
            "221275/221275 [==============================] - 26s 118us/step - loss: 4.4640 - acc: 0.2131\n",
            "Epoch 11/50\n",
            "221275/221275 [==============================] - 26s 117us/step - loss: 4.3635 - acc: 0.2181\n",
            "Epoch 12/50\n",
            "221275/221275 [==============================] - 26s 117us/step - loss: 4.2678 - acc: 0.2228\n",
            "Epoch 13/50\n",
            "221275/221275 [==============================] - 26s 117us/step - loss: 4.1776 - acc: 0.2284\n",
            "Epoch 14/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 4.0937 - acc: 0.2349\n",
            "Epoch 15/50\n",
            "221275/221275 [==============================] - 26s 117us/step - loss: 4.0178 - acc: 0.2407\n",
            "Epoch 16/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.9470 - acc: 0.2481\n",
            "Epoch 17/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.8830 - acc: 0.2544\n",
            "Epoch 18/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.8255 - acc: 0.2610\n",
            "Epoch 19/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.7734 - acc: 0.2664\n",
            "Epoch 20/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.7234 - acc: 0.2717\n",
            "Epoch 21/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.6793 - acc: 0.2772\n",
            "Epoch 22/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.6376 - acc: 0.2816\n",
            "Epoch 23/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.5978 - acc: 0.2863\n",
            "Epoch 24/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.5621 - acc: 0.2903\n",
            "Epoch 25/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.5282 - acc: 0.2944\n",
            "Epoch 26/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.4935 - acc: 0.2997\n",
            "Epoch 27/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.4629 - acc: 0.3033\n",
            "Epoch 28/50\n",
            "221275/221275 [==============================] - 26s 116us/step - loss: 3.4345 - acc: 0.3067\n",
            "Epoch 29/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.4044 - acc: 0.3103\n",
            "Epoch 30/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.3799 - acc: 0.3129\n",
            "Epoch 31/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.3536 - acc: 0.3166\n",
            "Epoch 32/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.3286 - acc: 0.3195\n",
            "Epoch 33/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.3061 - acc: 0.3222\n",
            "Epoch 34/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.2826 - acc: 0.3254\n",
            "Epoch 35/50\n",
            "221275/221275 [==============================] - 26s 115us/step - loss: 3.2607 - acc: 0.3282\n",
            "Epoch 36/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.2406 - acc: 0.3303\n",
            "Epoch 37/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.2193 - acc: 0.3330\n",
            "Epoch 38/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.2013 - acc: 0.3359\n",
            "Epoch 39/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.1825 - acc: 0.3383\n",
            "Epoch 40/50\n",
            "221275/221275 [==============================] - 25s 115us/step - loss: 3.1647 - acc: 0.3405\n",
            "Epoch 41/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.1449 - acc: 0.3432\n",
            "Epoch 42/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.1296 - acc: 0.3455\n",
            "Epoch 43/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.1145 - acc: 0.3463\n",
            "Epoch 44/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.0975 - acc: 0.3493\n",
            "Epoch 45/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.0827 - acc: 0.3509\n",
            "Epoch 46/50\n",
            "221275/221275 [==============================] - 25s 112us/step - loss: 3.0669 - acc: 0.3528\n",
            "Epoch 47/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.0519 - acc: 0.3555\n",
            "Epoch 48/50\n",
            "221275/221275 [==============================] - 25s 114us/step - loss: 3.0379 - acc: 0.3564\n",
            "Epoch 49/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.0264 - acc: 0.3577\n",
            "Epoch 50/50\n",
            "221275/221275 [==============================] - 25s 113us/step - loss: 3.0141 - acc: 0.3597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8vcMkTG2ZEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import plot_model\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtqEUoAxg2bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model for predictions. Note that this code can be run separately in a different environment (provided we have the model files).\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18t6o4TmOHJd",
        "colab_type": "code",
        "outputId": "061131eb-6b46-4a30-c054-ef23fda46e6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "plot_model(model, to_file=\"trigram_model.png\") #show_shapes=True,   expand_nested=True"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAIjCAYAAADRMKQFAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbS6tW2P_Qts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLXGphOoAgCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFwiReEW_sv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select a seed text\n",
        "seed_text = \"Yes he\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmSUAT-jAouc",
        "colab_type": "code",
        "outputId": "220942a4-56aa-4982-8aaa-baf1bcdafbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, 2, seed_text, 1)\n",
        "print(generated)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKc5wWbQBX4k",
        "colab_type": "code",
        "outputId": "81e08144-ffb5-43c5-8f97-f841be834edb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# code to confirm few n-grams generated by the LSTM model by comparing it with actual frequency based output\n",
        "blogs = open('republic.txt', 'rt')\n",
        "text = blogs.read()\n",
        "blogs.close()\n",
        "corpus = text\n",
        "# We will remove double quotes, !, ? $, #, etc\n",
        "# specify to translate chars \n",
        "str1 = \"\"\n",
        "# specify to replace with \n",
        "str2 = \"\"\n",
        "# delete chars \n",
        "str3 = \"\\\"!?#$%^&*+\"\n",
        "\n",
        "trg = corpus\n",
        "table = trg.maketrans(str1, str2, str3)\n",
        "corpus = trg.translate(table)\n",
        "words = corpus.split()\n",
        "\n",
        "esTrigrams = ngrams(words, 3)\n",
        "esTrigramFreq = collections.Counter(esTrigrams)\n",
        "esTrigramFreq.most_common(10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('as', 'well', 'as'), 113),\n",
              " (('to', 'be', 'the'), 109),\n",
              " (('is', 'to', 'be'), 76),\n",
              " (('which', 'is', 'the'), 74),\n",
              " (('Yes,', 'he', 'said,'), 74),\n",
              " (('are', 'to', 'be'), 70),\n",
              " (('the', 'nature', 'of'), 68),\n",
              " (('the', 'idea', 'of'), 67),\n",
              " (('there', 'is', 'no'), 66),\n",
              " (('he', 'said.', 'And'), 66)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVMP7FfKBvMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5eed0ae0-0095-4060-e1d9-4018e6063d72"
      },
      "source": [
        "# code to test the LSTM generated output with the frequency-based output over 100 predictions.\n",
        "testSet = esTrigramFreq.most_common(100)\n",
        "count=0\n",
        "for trigramTup in testSet:\n",
        "  trigram=trigramTup[0]\n",
        "  seed_text=trigram[0]+\" \"+trigram[1]\n",
        "  expected_text=trigram[2]\n",
        "  generated = generate_seq(model, tokenizer, 2, seed_text, 1)\n",
        "  # print(seed_text+\" : \"+\"(\"+expected_text+\" , \"+generated+\")\")\n",
        "  if generated.strip()== expected_text:\n",
        "    count+=1\n",
        "print (\"Accuracy: \",count/100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gZyluvTIA2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
