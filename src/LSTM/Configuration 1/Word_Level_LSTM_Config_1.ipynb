{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Level_LSTM_Config_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKDYuJbpI_xw",
        "colab_type": "text"
      },
      "source": [
        "**Word Level LSTM for quad-grams** (sequence length: 3)\n",
        "\n",
        "This model predicts a word given three prior words. The code broadly consists of three parts:\n",
        "\n",
        "*   Training the LSTM model and save it to a file.\n",
        "*   Load the model from the file.\n",
        "*   Calculate the accuracy of the model based on the frequency-based N-gram (five-grams in this case) counts.\n",
        "\n",
        "Pros:\n",
        "- Offers less sparsity and shorter sequence lengths in contrast to character-level alternatives.\n",
        "- No post-processing required.\n",
        "- Model trained on sequence length of n-words works well for all values less than n.\n",
        "- Good at capturing long-distance dependencies.\n",
        "\n",
        "Cons:\n",
        "- They are unable to generate a word which is unseen/rare during training, hence, suffer from the Out-Of-Vocabulary (OOV) problem. One solution is to have a large dictionary, but still, that increases the time and space complexity of the network and also, the same problem would appear for every new word.\n",
        "- Softmax used in the output layer is often computationaly intensive.\n",
        "- Harder to model languages with a rich morphology such as Finish, Turkish, Russian etc.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-1WNNP7lkPU",
        "colab_type": "code",
        "outputId": "25675f0c-74c2-49b2-91a4-065b62fefce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttetpn-tEBno",
        "colab_type": "code",
        "outputId": "40ffe863-03e1-40b2-8f21-b6564bd196a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd ../gdrive/My\\ Drive/NLP/Project"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/NLP/Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jL-wqa1qtj-",
        "colab_type": "code",
        "outputId": "dbcc8ebd-881e-4bda-aee1-7045cf4c1407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.txt  republic.txt   trigram_model.png\n",
            "model.h5  tokenizer.pkl  Word_Level_LSTM_Config_3.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER6sl6cjF7dY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuPdxkZ6X1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load the dataset\n",
        "in_filename = 'republic.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxKACktEhNQL",
        "colab_type": "code",
        "outputId": "5b7c5172-65cb-4f88-982d-47202443433a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "sequences[1:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [30, 1614, 5, 26, 1, 163, 2, 2549, 2550, 35, 44, 2871, 3, 28],\n",
              " [568, 44, 3940, 4907, 21, 37, 1062, 73, 235, 73, 248, 13],\n",
              " [2551, 163, 73, 157, 1, 379, 2, 1, 286, 264, 1178, 1325],\n",
              " [28, 30, 1614, 13, 3323, 35, 2552, 264, 1404],\n",
              " [],\n",
              " [],\n",
              " [2069, 1, 227],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7Df-vKhpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in sequences for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAOOpT55jARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 3\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(flat_list) - seq_length, 1):\n",
        "\tseq_in = flat_list[i:i + seq_length]\n",
        "\tseq_out = flat_list[i + seq_length]\n",
        "\tdataX.append(seq_in)\n",
        "\tdataY.append(seq_out)\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTpNMayajlYe",
        "colab_type": "code",
        "outputId": "e01d86fd-6a55-4a8d-a5c7-72f1ca83401e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patterns"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Ba1MRjlNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = array(dataX)\n",
        "dataY = array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqbJSLSj9aw",
        "colab_type": "code",
        "outputId": "e3ea1068-bb63-4eb8-860f-93bc38b4376d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataX.shape, dataY.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((221274, 3), (221274,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQJLFWPbqbl",
        "colab_type": "code",
        "outputId": "5f74de34-cb63-4294-ad55-e73a6ca13037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separate into input and output\n",
        "X, y = dataX, dataY\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = dataX.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 3, 50)             551800    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 3, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 11036)             1114636   \n",
            "=================================================================\n",
            "Total params: 1,817,336\n",
            "Trainable params: 1,817,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "221274/221274 [==============================] - 35s 158us/step - loss: 6.3750 - acc: 0.0790\n",
            "Epoch 2/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 5.8050 - acc: 0.1236\n",
            "Epoch 3/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 5.4397 - acc: 0.1562\n",
            "Epoch 4/50\n",
            "221274/221274 [==============================] - 32s 147us/step - loss: 5.2115 - acc: 0.1722\n",
            "Epoch 5/50\n",
            "221274/221274 [==============================] - 32s 147us/step - loss: 5.0412 - acc: 0.1833\n",
            "Epoch 6/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 4.8935 - acc: 0.1918\n",
            "Epoch 7/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 4.7542 - acc: 0.1991\n",
            "Epoch 8/50\n",
            "221274/221274 [==============================] - 33s 148us/step - loss: 4.6212 - acc: 0.2056\n",
            "Epoch 9/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 4.4958 - acc: 0.2118\n",
            "Epoch 10/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 4.3770 - acc: 0.2170\n",
            "Epoch 11/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 4.2624 - acc: 0.2237\n",
            "Epoch 12/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 4.1507 - acc: 0.2296\n",
            "Epoch 13/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 4.0434 - acc: 0.2368\n",
            "Epoch 14/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 3.9420 - acc: 0.2446\n",
            "Epoch 15/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 3.8468 - acc: 0.2547\n",
            "Epoch 16/50\n",
            "221274/221274 [==============================] - 31s 142us/step - loss: 3.7591 - acc: 0.2635\n",
            "Epoch 17/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 3.6772 - acc: 0.2731\n",
            "Epoch 18/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 3.6020 - acc: 0.2820\n",
            "Epoch 19/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 3.5320 - acc: 0.2920\n",
            "Epoch 20/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 3.4681 - acc: 0.2997\n",
            "Epoch 21/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 3.4073 - acc: 0.3084\n",
            "Epoch 22/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 3.3498 - acc: 0.3165\n",
            "Epoch 23/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 3.2970 - acc: 0.3238\n",
            "Epoch 24/50\n",
            "221274/221274 [==============================] - 32s 147us/step - loss: 3.2446 - acc: 0.3314\n",
            "Epoch 25/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 3.1977 - acc: 0.3383\n",
            "Epoch 26/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 3.1522 - acc: 0.3456\n",
            "Epoch 27/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 3.1074 - acc: 0.3516\n",
            "Epoch 28/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 3.0643 - acc: 0.3577\n",
            "Epoch 29/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 3.0273 - acc: 0.3642\n",
            "Epoch 30/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 2.9884 - acc: 0.3702\n",
            "Epoch 31/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 2.9515 - acc: 0.3754\n",
            "Epoch 32/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.9152 - acc: 0.3811\n",
            "Epoch 33/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 2.8816 - acc: 0.3869\n",
            "Epoch 34/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 2.8517 - acc: 0.3913\n",
            "Epoch 35/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.8185 - acc: 0.3963\n",
            "Epoch 36/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.7888 - acc: 0.4009\n",
            "Epoch 37/50\n",
            "221274/221274 [==============================] - 33s 148us/step - loss: 2.7611 - acc: 0.4058\n",
            "Epoch 38/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.7338 - acc: 0.4102\n",
            "Epoch 39/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 2.7052 - acc: 0.4152\n",
            "Epoch 40/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 2.6786 - acc: 0.4188\n",
            "Epoch 41/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 2.6539 - acc: 0.4246\n",
            "Epoch 42/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.6302 - acc: 0.4262\n",
            "Epoch 43/50\n",
            "221274/221274 [==============================] - 32s 145us/step - loss: 2.6062 - acc: 0.4313\n",
            "Epoch 44/50\n",
            "221274/221274 [==============================] - 31s 142us/step - loss: 2.5859 - acc: 0.4345\n",
            "Epoch 45/50\n",
            "221274/221274 [==============================] - 32s 143us/step - loss: 2.5632 - acc: 0.4382\n",
            "Epoch 46/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 2.5424 - acc: 0.4412\n",
            "Epoch 47/50\n",
            "221274/221274 [==============================] - 32s 146us/step - loss: 2.5208 - acc: 0.4451\n",
            "Epoch 48/50\n",
            "221274/221274 [==============================] - 31s 142us/step - loss: 2.5014 - acc: 0.4485\n",
            "Epoch 49/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.4843 - acc: 0.4508\n",
            "Epoch 50/50\n",
            "221274/221274 [==============================] - 32s 144us/step - loss: 2.4627 - acc: 0.4540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHqvYEgAGRcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import plot_model\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTa1Hhm7eprb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKNQiaG7PMpQ",
        "colab_type": "code",
        "outputId": "c54a4c2a-686d-4875-cc07-b691038f0e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "plot_model(model, to_file=\"trigram_model.png\") #show_shapes=True,   expand_nested=True"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAIjCAYAAADRMKQFAAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\nIsCbLur0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtqEUoAxg2bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlbs99JkF9jJ",
        "colab_type": "code",
        "outputId": "32936390-a97e-4382-a1c1-6e9430d5719c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# select a seed text\n",
        "seed_text = \"what do you\"\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, 3, seed_text, 1)\n",
        "print(generated)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukq8XhNbGEDL",
        "colab_type": "code",
        "outputId": "7c6bc668-a53a-4471-96d0-a95c7e31383d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# code to confirm the n-grams generated by the our model by comparing it with actual frequency based output\n",
        "blogs = open('republic.txt', 'rt')\n",
        "text = blogs.read()\n",
        "blogs.close()\n",
        "corpus = text\n",
        "# We will remove double quotes, !, ? $, #, etc\n",
        "# specify to translate chars \n",
        "str1 = \"\"\n",
        "# specify to replace with \n",
        "str2 = \"\"\n",
        "# delete chars \n",
        "str3 = \"\\\"!?#$%^&*+\"\n",
        "\n",
        "trg = corpus\n",
        "table = trg.maketrans(str1, str2, str3)\n",
        "corpus = trg.translate(table)\n",
        "words = corpus.split()\n",
        "\n",
        "esQuadgrams = ngrams(words, 4)\n",
        "esQuadgramFreq = collections.Counter(esQuadgrams)\n",
        "esQuadgramFreq.most_common(10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('for', 'the', 'sake', 'of'), 28),\n",
              " (('Very', 'true,', 'he', 'said.'), 26),\n",
              " (('the', 'interest', 'of', 'the'), 25),\n",
              " (('What', 'do', 'you', 'mean'), 24),\n",
              " (('at', 'the', 'same', 'time'), 22),\n",
              " (('the', 'rest', 'of', 'the'), 21),\n",
              " (('Yes,', 'he', 'said,', 'that'), 21),\n",
              " (('in', 'the', 'case', 'of'), 20),\n",
              " (('as', 'well', 'as', 'of'), 18),\n",
              " (('the', 'idea', 'of', 'good'), 18)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20IVh3qLLCPG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb8986ee-efee-45db-aaa9-ad3bdf8d6cb1"
      },
      "source": [
        "# code to test the LSTM generated output with the frequency-based output over 100 predictions.\n",
        "testSet = esQuadgramFreq.most_common(100)\n",
        "count=0\n",
        "for quadgramTup in testSet:\n",
        "  quadgram=quadgramTup[0]\n",
        "  seed_text=quadgram[0]+\" \"+quadgram[1]+\" \"+quadgram[2]\n",
        "  expected_text=quadgram[3]\n",
        "  generated = generate_seq(model, tokenizer, 3, seed_text, 1)\n",
        "  # print(seed_text+\" : \"+\"(\"+expected_text+\" , \"+generated+\")\")\n",
        "  if generated.strip()== expected_text:\n",
        "    count+=1\n",
        "print (\"Accuracy: \",count/100)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRtKAjnqcNp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
